{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1t8_vq0D7kE76ZeqUh_YVehu6l09ebDPg",
      "authorship_tag": "ABX9TyMifluIWMjTzOL+B4kM8tim",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vjy14/golf-/blob/main/golf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S1xe0weeP8PS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/ct new/train'\n",
        "test_dir = '/content/drive/MyDrive/ct new/test'\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJySkBmId0aL",
        "outputId": "6dad12dc-84de-418e-ecf5-068150049689"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 252 images belonging to 2 classes.\n",
            "Found 21 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_tf = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3),classes=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh8C_Sxnd6uG",
        "outputId": "fe456905-c075-4658-c112-c6228315162f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_tf.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OOsNXxtGeWpP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential,load_model,Model\n",
        "from keras.layers import Conv2D,MaxPool2D,AveragePooling2D,Dense,Flatten,ZeroPadding2D,BatchNormalization,Activation,Add,Input,Dropout,GlobalAveragePooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input"
      ],
      "metadata": {
        "id": "vSX_FWhYecB2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_tf.trainable=False\n",
        "\n",
        "pt=Input(shape=(224,224,3))\n",
        "func=tensorflow.cast(pt,tensorflow.float32)\n",
        "x=preprocess_input(func) #This function used to zero-center each color channel wrt Imagenet dataset\n",
        "model_resnet=base_model_tf(x,training=False)\n",
        "model_resnet=GlobalAveragePooling2D()(model_resnet)\n",
        "model_resnet=Dense(128,activation='relu')(model_resnet)\n",
        "model_resnet=Dense(64,activation='relu')(model_resnet)\n",
        "model_resnet=Dense(2,activation='softmax')(model_resnet)\n",
        "\n",
        "\n",
        "model_main=Model(inputs=pt,outputs=model_resnet)\n",
        "model_main.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDAkBUWYesq4",
        "outputId": "aba74f79-305f-4ad5-e024-61fd64138c49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " tf.cast (TFOpLambda)        (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " tf.__operators__.getitem (  (None, 224, 224, 3)       0         \n",
            " SlicingOpLambda)                                                \n",
            "                                                                 \n",
            " tf.nn.bias_add (TFOpLambda  (None, 224, 224, 3)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23858370 (91.01 MB)\n",
            "Trainable params: 270658 (1.03 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_main.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "kWdr3LYxe2Ni"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_generator.samples)\n",
        "print(test_generator.samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snfm5nZRgWfu",
        "outputId": "eb1d45b6-3e54-461b-fe7a-45026bb3f76c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252\n",
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_main.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=20,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=len(test_generator)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra6wFhgUe-7l",
        "outputId": "c5a64e4f-5296-4b9a-cb7f-c0cdc988588d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.6409 - accuracy: 0.6071 - val_loss: 0.6749 - val_accuracy: 0.4762\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 6s 758ms/step - loss: 0.6436 - accuracy: 0.5873 - val_loss: 0.6571 - val_accuracy: 0.6667\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 5s 615ms/step - loss: 0.6367 - accuracy: 0.6468 - val_loss: 0.6823 - val_accuracy: 0.5714\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 6s 749ms/step - loss: 0.6440 - accuracy: 0.5635 - val_loss: 0.7028 - val_accuracy: 0.5714\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 6s 693ms/step - loss: 0.6480 - accuracy: 0.6389 - val_loss: 0.6682 - val_accuracy: 0.5714\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 5s 616ms/step - loss: 0.6564 - accuracy: 0.6032 - val_loss: 0.7381 - val_accuracy: 0.4762\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 5s 599ms/step - loss: 0.6678 - accuracy: 0.5516 - val_loss: 0.7116 - val_accuracy: 0.5238\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 6s 779ms/step - loss: 0.6270 - accuracy: 0.5913 - val_loss: 0.6453 - val_accuracy: 0.6667\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 5s 627ms/step - loss: 0.6061 - accuracy: 0.6667 - val_loss: 0.6579 - val_accuracy: 0.6667\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 5s 659ms/step - loss: 0.6018 - accuracy: 0.7183 - val_loss: 0.6574 - val_accuracy: 0.6190\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 5s 594ms/step - loss: 0.6166 - accuracy: 0.6667 - val_loss: 0.7244 - val_accuracy: 0.5714\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 6s 768ms/step - loss: 0.6358 - accuracy: 0.6389 - val_loss: 0.6505 - val_accuracy: 0.6190\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 5s 675ms/step - loss: 0.6395 - accuracy: 0.6111 - val_loss: 0.6863 - val_accuracy: 0.4762\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 5s 580ms/step - loss: 0.6741 - accuracy: 0.5556 - val_loss: 0.7141 - val_accuracy: 0.5714\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 5s 589ms/step - loss: 0.6320 - accuracy: 0.6032 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 6s 764ms/step - loss: 0.6459 - accuracy: 0.6389 - val_loss: 0.6364 - val_accuracy: 0.5714\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 6s 738ms/step - loss: 0.6183 - accuracy: 0.6111 - val_loss: 0.6676 - val_accuracy: 0.6190\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 5s 603ms/step - loss: 0.6157 - accuracy: 0.6905 - val_loss: 0.6272 - val_accuracy: 0.6667\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 6s 745ms/step - loss: 0.5973 - accuracy: 0.6825 - val_loss: 0.6254 - val_accuracy: 0.6190\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 6s 746ms/step - loss: 0.5841 - accuracy: 0.7103 - val_loss: 0.6355 - val_accuracy: 0.5714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e0e5efcd5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy =model_main.evaluate(test_generator)\n",
        "print(f'Test accuracy: {accuracy[1]*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_17L5rddh7ZU",
        "outputId": "6f9fc4e4-72a0-4b0b-fc62-41a785519a24"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 444ms/step - loss: 0.6338 - accuracy: 0.6190\n",
            "Test accuracy: 61.90%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_main.save('golf.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw3elqKSia2T",
        "outputId": "afec66c5-9f72-4436-9762-ccd2957007b7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "model = tf.keras.models.load_model('golf.h5')\n",
        "\n",
        "test_image_path = '/content/drive/MyDrive/ct new/train/ct train/jason-pofahl-_Vuvc7-4ToA-unsplash_jpg.rf.9f8671127cef149f4deb7257ba2078dc.jpg'\n",
        "img = image.load_img(test_image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0\n",
        "\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "class_labels = ['correct pose','wrong pose']\n",
        "predicted_class = class_labels[np.argmax(predictions)]\n",
        "\n",
        "print(f'The predicted class is: {predicted_class}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqvmk_f7iq0L",
        "outputId": "f8c0f8f0-ebff-4c9b-b1f9-7bb4f9b8e95a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 869ms/step\n",
            "The predicted class is: correct pose\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qi9uqRTyinnE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}